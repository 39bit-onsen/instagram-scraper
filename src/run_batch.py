#!/usr/bin/env python3
"""
Instagram ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ ãƒãƒƒãƒå‡¦ç†
CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¤‡æ•°ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’èª­ã¿è¾¼ã¿ã€ä¸€æ‹¬å‡¦ç†ã‚’å®Ÿè¡Œ
"""

import sys
import os
import csv
import argparse
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime
import time

# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã‚’è¨­å®š
sys.path.append(os.path.dirname(__file__))

try:
    from scraper.fetch_tag import fetch_hashtag_data
    from scraper.data_manager import DataManager, create_sample_tags_csv
    from scraper.utils import setup_logger
    from tqdm import tqdm
except ImportError as e:
    print(f"âŒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    print("ä»®æƒ³ç’°å¢ƒãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆã•ã‚Œã€ä¾å­˜é–¢ä¿‚ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
    sys.exit(1)


class BatchProcessor:
    """ãƒãƒƒãƒå‡¦ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, headless: bool = True, delay: float = 2.0):
        """
        åˆæœŸåŒ–
        
        Args:
            headless: ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰
            delay: ã‚¿ã‚°é–“ã®å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰
        """
        self.headless = headless
        self.delay = delay
        self.data_manager = DataManager()
        self.logger = setup_logger("batch_processor")
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            'total_tags': 0,
            'success_count': 0,
            'error_count': 0,
            'start_time': None,
            'end_time': None
        }
        
    def load_hashtags_from_csv(self, csv_file: str) -> List[str]:
        """
        CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿
        
        Args:
            csv_file: CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã®ãƒªã‚¹ãƒˆ
        """
        hashtags = []
        
        try:
            with open(csv_file, 'r', encoding='utf-8-sig') as f:
                # CSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’è‡ªå‹•æ¤œå‡º
                sample = f.read(1024)
                f.seek(0)
                
                sniffer = csv.Sniffer()
                has_header = sniffer.has_header(sample)
                
                reader = csv.reader(f)
                
                # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
                if has_header:
                    next(reader)
                
                # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’èª­ã¿è¾¼ã¿
                for row in reader:
                    if row and len(row) > 0:
                        hashtag = row[0].strip().lstrip('#')
                        if hashtag:
                            hashtags.append(hashtag)
                            
            self.logger.info(f"âœ… CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ {len(hashtags)} å€‹ã®ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            return hashtags
            
        except FileNotFoundError:
            self.logger.error(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_file}")
            return []
        except Exception as e:
            self.logger.error(f"âŒ CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def process_hashtags(self, hashtags: List[str], batch_name: str = None) -> List[Dict[str, Any]]:
        """
        ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã®ä¸€æ‹¬å‡¦ç†
        
        Args:
            hashtags: å‡¦ç†ã™ã‚‹ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã®ãƒªã‚¹ãƒˆ
            batch_name: ãƒãƒƒãƒåï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ï¼‰
            
        Returns:
            å‡¦ç†çµæœã®ãƒªã‚¹ãƒˆ
        """
        if not hashtags:
            self.logger.warning("å‡¦ç†ã™ã‚‹ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ãŒã‚ã‚Šã¾ã›ã‚“")
            return []
        
        # çµ±è¨ˆæƒ…å ±åˆæœŸåŒ–
        self.stats['total_tags'] = len(hashtags)
        self.stats['start_time'] = datetime.now()
        
        self.logger.info(f"=== ãƒãƒƒãƒå‡¦ç†é–‹å§‹ ===")
        self.logger.info(f"å‡¦ç†å¯¾è±¡: {len(hashtags)} å€‹ã®ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°")
        self.logger.info(f"ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if self.headless else 'ç„¡åŠ¹'}")
        self.logger.info(f"ã‚¿ã‚°é–“å¾…æ©Ÿæ™‚é–“: {self.delay} ç§’")
        
        results = []
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãã§å‡¦ç†
        with tqdm(total=len(hashtags), desc="ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°å‡¦ç†", unit="tags") as pbar:
            for i, hashtag in enumerate(hashtags):
                try:
                    # é€²æ—è¡¨ç¤º
                    pbar.set_description(f"å‡¦ç†ä¸­: #{hashtag}")
                    self.logger.info(f"[{i+1}/{len(hashtags)}] #{hashtag} ã‚’å‡¦ç†ä¸­...")
                    
                    # ãƒ‡ãƒ¼ã‚¿å–å¾—
                    result = fetch_hashtag_data(hashtag, self.headless)
                    results.append(result)
                    
                    # çµæœãƒ­ã‚°
                    if result.get('error'):
                        self.logger.warning(f"âŒ #{hashtag}: {result['error']}")
                        self.stats['error_count'] += 1
                    else:
                        post_count = result.get('post_count', 0)
                        self.logger.info(f"âœ… #{hashtag}: {post_count:,} æŠ•ç¨¿")
                        self.stats['success_count'] += 1
                    
                    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°
                    pbar.update(1)
                    
                    # å¾…æ©Ÿï¼ˆæœ€å¾Œã®ã‚¿ã‚°ä»¥å¤–ï¼‰
                    if i < len(hashtags) - 1:
                        self.logger.debug(f"{self.delay} ç§’å¾…æ©Ÿä¸­...")
                        time.sleep(self.delay)
                        
                except KeyboardInterrupt:
                    self.logger.warning("âš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
                    break
                    
                except Exception as e:
                    error_msg = f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(e)}"
                    self.logger.error(f"âŒ #{hashtag}: {error_msg}")
                    
                    # ã‚¨ãƒ©ãƒ¼çµæœã‚’è¨˜éŒ²
                    error_result = {
                        'hashtag': hashtag,
                        'error': error_msg,
                        'post_count': 0,
                        'related_tags': [],
                        'top_posts': [],
                        'scraped_at': time.time()
                    }
                    results.append(error_result)
                    self.stats['error_count'] += 1
                    
                    pbar.update(1)
        
        # çµ±è¨ˆæƒ…å ±æ›´æ–°
        self.stats['end_time'] = datetime.now()
        
        # çµæœä¿å­˜
        if results:
            try:
                csv_path, json_path = self.data_manager.save_batch_results(results, batch_name)
                self.logger.info(f"ğŸ’¾ çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ:")
                self.logger.info(f"   CSV: {csv_path}")
                self.logger.info(f"   JSON: {json_path}")
            except Exception as e:
                self.logger.error(f"âŒ çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        
        # å‡¦ç†å®Œäº†ãƒ­ã‚°
        self.print_summary()
        
        return results
    
    def print_summary(self):
        """å‡¦ç†çµæœã®ã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        if self.stats['start_time'] and self.stats['end_time']:
            duration = self.stats['end_time'] - self.stats['start_time']
            duration_str = str(duration).split('.')[0]  # ç§’ä»¥ä¸‹ã‚’åˆ‡ã‚Šæ¨ã¦
        else:
            duration_str = "ä¸æ˜"
        
        self.logger.info("=== å‡¦ç†çµæœã‚µãƒãƒªãƒ¼ ===")
        self.logger.info(f"ç·ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°æ•°: {self.stats['total_tags']}")
        self.logger.info(f"æˆåŠŸ: {self.stats['success_count']}")
        self.logger.info(f"å¤±æ•—: {self.stats['error_count']}")
        self.logger.info(f"æˆåŠŸç‡: {(self.stats['success_count'] / max(self.stats['total_tags'], 1)) * 100:.1f}%")
        self.logger.info(f"å‡¦ç†æ™‚é–“: {duration_str}")
        
        if self.stats['success_count'] > 0:
            avg_time = duration.total_seconds() / self.stats['success_count']
            self.logger.info(f"å¹³å‡å‡¦ç†æ™‚é–“: {avg_time:.1f}ç§’/ã‚¿ã‚°")


def create_default_tags_file():
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¿ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
    config_dir = Path("config")
    tags_file = config_dir / "tags.csv"
    
    if not tags_file.exists():
        print("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¿ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ã„ã¾ã™...")
        create_sample_tags_csv(str(tags_file))
        print(f"âœ… ã‚¿ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ: {tags_file}")
        print("ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†ã—ã¦ã€å–å¾—ã—ãŸã„ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return str(tags_file)
    else:
        return str(tags_file)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="Instagram ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ ãƒãƒƒãƒå‡¦ç†",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  python src/run_batch.py                          # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨
  python src/run_batch.py -f config/my_tags.csv   # ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨
  python src/run_batch.py --gui                   # GUIè¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰
  python src/run_batch.py --delay 5               # 5ç§’é–“éš”ã§å®Ÿè¡Œ
        """
    )
    
    parser.add_argument(
        "-f", "--file",
        help="ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: config/tags.csv)",
        default=None
    )
    
    parser.add_argument(
        "--gui",
        action="store_true",
        help="GUIãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ã‚’è¡¨ç¤ºï¼‰"
    )
    
    parser.add_argument(
        "--delay",
        type=float,
        default=2.0,
        help="ã‚¿ã‚°é–“ã®å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2.0ï¼‰"
    )
    
    parser.add_argument(
        "--batch-name",
        help="ãƒãƒƒãƒåï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ï¼‰"
    )
    
    parser.add_argument(
        "--create-sample",
        action="store_true",
        help="ã‚µãƒ³ãƒ—ãƒ«ã‚¿ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦çµ‚äº†"
    )
    
    args = parser.parse_args()
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆãƒ¢ãƒ¼ãƒ‰
    if args.create_sample:
        sample_file = create_sample_tags_csv()
        print(f"ã‚µãƒ³ãƒ—ãƒ«ã‚¿ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ: {sample_file}")
        return
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®æ±ºå®š
    if args.file:
        csv_file = args.file
    else:
        csv_file = create_default_tags_file()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    if not Path(csv_file).exists():
        print(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_file}")
        print("--create-sample ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã§ãã¾ã™")
        return
    
    print("=== Instagram ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ ãƒãƒƒãƒå‡¦ç† ===")
    print(f"CSVãƒ•ã‚¡ã‚¤ãƒ«: {csv_file}")
    print(f"å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: {'GUIè¡¨ç¤º' if args.gui else 'ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹'}")
    print(f"å¾…æ©Ÿæ™‚é–“: {args.delay}ç§’")
    
    # ç¢ºèªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    try:
        response = input("\nå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã‹ï¼Ÿ (y/N): ").strip().lower()
        if response not in ['y', 'yes']:
            print("å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã—ãŸã€‚")
            return
    except KeyboardInterrupt:
        print("\nå‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã—ãŸã€‚")
        return
    
    # ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
    try:
        processor = BatchProcessor(
            headless=not args.gui,
            delay=args.delay
        )
        
        # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°èª­ã¿è¾¼ã¿
        hashtags = processor.load_hashtags_from_csv(csv_file)
        
        if not hashtags:
            print("âŒ å‡¦ç†ã™ã‚‹ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # å‡¦ç†å®Ÿè¡Œ
        results = processor.process_hashtags(hashtags, args.batch_name)
        
        if results:
            print(f"\nğŸ‰ ãƒãƒƒãƒå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            print(f"æˆåŠŸ: {processor.stats['success_count']}ä»¶")
            print(f"å¤±æ•—: {processor.stats['error_count']}ä»¶")
        else:
            print("âŒ å‡¦ç†çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            
    except KeyboardInterrupt:
        print("\nâš ï¸ å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


if __name__ == "__main__":
    main()