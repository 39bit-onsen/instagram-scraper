#!/usr/bin/env python3
"""
Instagram ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ ãƒ‡ãƒ¼ã‚¿ç®¡ç†
CSV/JSONå½¢å¼ã§ã®ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿æ©Ÿèƒ½ã‚’æä¾›
"""

import json
import csv
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Union
import pandas as pd

from .utils import create_directory_if_not_exists, get_current_month_dir, setup_logger


class DataManager:
    """ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ»ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, base_dir: str = "data/hashtags"):
        """
        åˆæœŸåŒ–
        
        Args:
            base_dir: ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.base_dir = Path(base_dir)
        self.logger = setup_logger("data_manager")
        
        # ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        create_directory_if_not_exists(self.base_dir)
    
    def save_hashtag_data(self, hashtag_data: Dict[str, Any], 
                         custom_filename: Optional[str] = None) -> tuple[str, str]:
        """
        ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’CSV/JSONå½¢å¼ã§ä¿å­˜
        
        Args:
            hashtag_data: ä¿å­˜ã™ã‚‹ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ãƒ‡ãƒ¼ã‚¿
            custom_filename: ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ‹¡å¼µå­ãªã—ï¼‰
            
        Returns:
            (CSV filepath, JSON filepath)
        """
        try:
            # ç¾åœ¨ã®å¹´æœˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
            month_dir = get_current_month_dir(self.base_dir)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
            if custom_filename:
                base_filename = custom_filename
            else:
                hashtag = hashtag_data.get('hashtag', 'unknown')
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                base_filename = f"{hashtag}_{timestamp}"
            
            csv_filepath = month_dir / f"{base_filename}.csv"
            json_filepath = month_dir / f"{base_filename}.json"
            
            # CSVå½¢å¼ã§ä¿å­˜
            csv_path = self._save_to_csv(hashtag_data, csv_filepath)
            
            # JSONå½¢å¼ã§ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¿å­˜
            json_path = self._save_to_json(hashtag_data, json_filepath)
            
            self.logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {base_filename}")
            self.logger.info(f"   CSV: {csv_path}")
            self.logger.info(f"   JSON: {json_path}")
            
            return str(csv_path), str(json_path)
            
        except Exception as e:
            self.logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _save_to_csv(self, hashtag_data: Dict[str, Any], filepath: Path) -> str:
        """CSVå½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ä¿å­˜"""
        try:
            # CSVãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            csv_rows = []
            
            # ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿è¡Œ
            main_row = {
                'hashtag': hashtag_data.get('hashtag', ''),
                'url': hashtag_data.get('url', ''),
                'post_count': hashtag_data.get('post_count', 0),
                'related_tags_count': len(hashtag_data.get('related_tags', [])),
                'top_posts_count': len(hashtag_data.get('top_posts', [])),
                'related_tags': '|'.join(hashtag_data.get('related_tags', [])),
                'scraped_at': datetime.fromtimestamp(
                    hashtag_data.get('scraped_at', 0)
                ).strftime('%Y-%m-%d %H:%M:%S') if hashtag_data.get('scraped_at') else '',
                'error': hashtag_data.get('error', ''),
                'top_post_urls': '|'.join([
                    post.get('url', '') for post in hashtag_data.get('top_posts', [])
                ]),
                'top_post_types': '|'.join([
                    post.get('type', '') for post in hashtag_data.get('top_posts', [])
                ])
            }
            csv_rows.append(main_row)
            
            # DataFrameã«å¤‰æ›ã—ã¦ä¿å­˜
            df = pd.DataFrame(csv_rows)
            df.to_csv(filepath, index=False, encoding='utf-8-sig')
            
            return str(filepath)
            
        except Exception as e:
            self.logger.error(f"CSVä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _save_to_json(self, hashtag_data: Dict[str, Any], filepath: Path) -> str:
        """JSONå½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ä¿å­˜"""
        try:
            # æ—¥æ™‚ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
            json_data = hashtag_data.copy()
            if 'scraped_at' in json_data and json_data['scraped_at']:
                json_data['scraped_at_formatted'] = datetime.fromtimestamp(
                    json_data['scraped_at']
                ).strftime('%Y-%m-%d %H:%M:%S')
            
            # JSONä¿å­˜
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(json_data, f, indent=2, ensure_ascii=False)
            
            return str(filepath)
            
        except Exception as e:
            self.logger.error(f"JSONä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def save_batch_results(self, hashtag_results: List[Dict[str, Any]], 
                          batch_name: Optional[str] = None) -> tuple[str, str]:
        """
        è¤‡æ•°ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã®çµæœã‚’ä¸€æ‹¬ä¿å­˜
        
        Args:
            hashtag_results: ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°çµæœã®ãƒªã‚¹ãƒˆ
            batch_name: ãƒãƒƒãƒå
            
        Returns:
            (CSV filepath, JSON filepath)
        """
        try:
            # ç¾åœ¨ã®å¹´æœˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
            month_dir = get_current_month_dir(self.base_dir)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
            if batch_name:
                base_filename = f"batch_{batch_name}"
            else:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                base_filename = f"batch_{timestamp}"
            
            csv_filepath = month_dir / f"{base_filename}.csv"
            json_filepath = month_dir / f"{base_filename}.json"
            
            # CSVå½¢å¼ã§ä¿å­˜
            csv_path = self._save_batch_to_csv(hashtag_results, csv_filepath)
            
            # JSONå½¢å¼ã§ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¿å­˜
            json_path = self._save_batch_to_json(hashtag_results, json_filepath)
            
            self.logger.info(f"âœ… ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {len(hashtag_results)}ä»¶")
            self.logger.info(f"   CSV: {csv_path}")
            self.logger.info(f"   JSON: {json_path}")
            
            return str(csv_path), str(json_path)
            
        except Exception as e:
            self.logger.error(f"âŒ ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _save_batch_to_csv(self, hashtag_results: List[Dict[str, Any]], 
                          filepath: Path) -> str:
        """ãƒãƒƒãƒçµæœã‚’CSVå½¢å¼ã§ä¿å­˜"""
        try:
            csv_rows = []
            
            for hashtag_data in hashtag_results:
                row = {
                    'hashtag': hashtag_data.get('hashtag', ''),
                    'url': hashtag_data.get('url', ''),
                    'post_count': hashtag_data.get('post_count', 0),
                    'related_tags_count': len(hashtag_data.get('related_tags', [])),
                    'top_posts_count': len(hashtag_data.get('top_posts', [])),
                    'related_tags': '|'.join(hashtag_data.get('related_tags', [])),
                    'scraped_at': datetime.fromtimestamp(
                        hashtag_data.get('scraped_at', 0)
                    ).strftime('%Y-%m-%d %H:%M:%S') if hashtag_data.get('scraped_at') else '',
                    'error': hashtag_data.get('error', ''),
                    'success': 'Yes' if not hashtag_data.get('error') else 'No'
                }
                csv_rows.append(row)
            
            # DataFrameã«å¤‰æ›ã—ã¦ä¿å­˜
            df = pd.DataFrame(csv_rows)
            df.to_csv(filepath, index=False, encoding='utf-8-sig')
            
            return str(filepath)
            
        except Exception as e:
            self.logger.error(f"ãƒãƒƒãƒCSVä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _save_batch_to_json(self, hashtag_results: List[Dict[str, Any]], 
                           filepath: Path) -> str:
        """ãƒãƒƒãƒçµæœã‚’JSONå½¢å¼ã§ä¿å­˜"""
        try:
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãã§ä¿å­˜
            batch_data = {
                'batch_info': {
                    'total_hashtags': len(hashtag_results),
                    'successful_count': len([r for r in hashtag_results if not r.get('error')]),
                    'failed_count': len([r for r in hashtag_results if r.get('error')]),
                    'saved_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                },
                'results': hashtag_results
            }
            
            # æ—¥æ™‚ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
            for result in batch_data['results']:
                if 'scraped_at' in result and result['scraped_at']:
                    result['scraped_at_formatted'] = datetime.fromtimestamp(
                        result['scraped_at']
                    ).strftime('%Y-%m-%d %H:%M:%S')
            
            # JSONä¿å­˜
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(batch_data, f, indent=2, ensure_ascii=False)
            
            return str(filepath)
            
        except Exception as e:
            self.logger.error(f"ãƒãƒƒãƒJSONä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def load_csv_data(self, filepath: Union[str, Path]) -> pd.DataFrame:
        """
        CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        
        Args:
            filepath: CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            DataFrameã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        try:
            df = pd.read_csv(filepath, encoding='utf-8-sig')
            self.logger.info(f"âœ… CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}è¡Œ")
            return df
            
        except Exception as e:
            self.logger.error(f"âŒ CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def load_json_data(self, filepath: Union[str, Path]) -> Dict[str, Any]:
        """
        JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        
        Args:
            filepath: JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            è¾æ›¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.logger.info(f"âœ… JSONãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†")
            return data
            
        except Exception as e:
            self.logger.error(f"âŒ JSONèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def list_saved_files(self, month: Optional[str] = None) -> Dict[str, List[str]]:
        """
        ä¿å­˜æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€è¦§ã‚’å–å¾—
        
        Args:
            month: å¯¾è±¡æœˆï¼ˆYYYYMMå½¢å¼ã€æœªæŒ‡å®šæ™‚ã¯å…¨æœˆï¼‰
            
        Returns:
            ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã®è¾æ›¸
        """
        try:
            files = {'csv': [], 'json': []}
            
            if month:
                # ç‰¹å®šæœˆã®ãƒ•ã‚¡ã‚¤ãƒ«
                month_dir = self.base_dir / month
                if month_dir.exists():
                    files['csv'] = list(month_dir.glob('*.csv'))
                    files['json'] = list(month_dir.glob('*.json'))
            else:
                # å…¨æœˆã®ãƒ•ã‚¡ã‚¤ãƒ«
                for month_dir in self.base_dir.iterdir():
                    if month_dir.is_dir():
                        files['csv'].extend(month_dir.glob('*.csv'))
                        files['json'].extend(month_dir.glob('*.json'))
            
            # ãƒ‘ã‚¹ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
            files['csv'] = [str(f) for f in files['csv']]
            files['json'] = [str(f) for f in files['json']]
            
            self.logger.info(f"ä¿å­˜æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«: CSV {len(files['csv'])}å€‹, JSON {len(files['json'])}å€‹")
            
            return files
            
        except Exception as e:
            self.logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {'csv': [], 'json': []}
    
    def get_summary_stats(self) -> Dict[str, Any]:
        """
        ä¿å­˜ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        
        Returns:
            çµ±è¨ˆæƒ…å ±ã®è¾æ›¸
        """
        try:
            stats = {
                'total_files': 0,
                'total_hashtags': 0,
                'months': [],
                'largest_hashtag': None,
                'most_recent': None
            }
            
            # æœˆåˆ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’èµ°æŸ»
            for month_dir in self.base_dir.iterdir():
                if month_dir.is_dir():
                    month_name = month_dir.name
                    stats['months'].append(month_name)
                    
                    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
                    csv_files = list(month_dir.glob('*.csv'))
                    stats['total_files'] += len(csv_files)
                    
                    # ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰çµ±è¨ˆã‚’å–å¾—
                    for csv_file in csv_files:
                        try:
                            df = pd.read_csv(csv_file, encoding='utf-8-sig')
                            stats['total_hashtags'] += len(df)
                            
                            # æœ€å¤§æŠ•ç¨¿æ•°ã®ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’è¨˜éŒ²
                            if not df.empty and 'post_count' in df.columns:
                                max_posts_row = df.loc[df['post_count'].idxmax()]
                                if (not stats['largest_hashtag'] or 
                                    max_posts_row['post_count'] > stats['largest_hashtag']['post_count']):
                                    stats['largest_hashtag'] = {
                                        'hashtag': max_posts_row.get('hashtag', ''),
                                        'post_count': max_posts_row.get('post_count', 0)
                                    }
                        except Exception:
                            continue
            
            # æœ€æ–°æœˆã‚’ã‚½ãƒ¼ãƒˆ
            if stats['months']:
                stats['months'].sort(reverse=True)
                stats['most_recent'] = stats['months'][0]
            
            return stats
            
        except Exception as e:
            self.logger.error(f"âŒ çµ±è¨ˆæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}


def create_sample_tags_csv(filepath: str = "config/sample_tags.csv") -> str:
    """
    ã‚µãƒ³ãƒ—ãƒ«ã‚¿ã‚°CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    
    Args:
        filepath: ä½œæˆã™ã‚‹CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        
    Returns:
        ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
    sample_tags = [
        "citywalkhk",
        "japantravel", 
        "foodie",
        "photography",
        "nature",
        "streetart",
        "sunset",
        "coffee",
        "workout",
        "art"
    ]
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    file_path = Path(filepath)
    create_directory_if_not_exists(file_path.parent)
    
    # CSVä½œæˆ
    with open(file_path, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow(['hashtag'])  # ãƒ˜ãƒƒãƒ€ãƒ¼
        for tag in sample_tags:
            writer.writerow([tag])
    
    print(f"âœ… ã‚µãƒ³ãƒ—ãƒ«ã‚¿ã‚°CSVã‚’ä½œæˆã—ã¾ã—ãŸ: {filepath}")
    return str(file_path)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•° - ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("=== ãƒ‡ãƒ¼ã‚¿ç®¡ç†æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ ===")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
    dm = DataManager()
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    sample_data = {
        'hashtag': 'test',
        'url': 'https://www.instagram.com/explore/tags/test/',
        'post_count': 12345,
        'related_tags': ['testdata', 'sample', 'demo'],
        'top_posts': [
            {'url': 'https://www.instagram.com/p/test1/', 'type': 'image'},
            {'url': 'https://www.instagram.com/p/test2/', 'type': 'video'}
        ],
        'scraped_at': time.time(),
        'error': None
    }
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ†ã‚¹ãƒˆ
        csv_path, json_path = dm.save_hashtag_data(sample_data, "test_data")
        print(f"âœ… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
        print(f"   CSV: {csv_path}")
        print(f"   JSON: {json_path}")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
        loaded_df = dm.load_csv_data(csv_path)
        print(f"âœ… CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(loaded_df)}è¡Œ")
        
        # çµ±è¨ˆæƒ…å ±ãƒ†ã‚¹ãƒˆ
        stats = dm.get_summary_stats()
        print(f"âœ… çµ±è¨ˆæƒ…å ±:")
        print(f"   ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats.get('total_files', 0)}")
        print(f"   ç·ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°æ•°: {stats.get('total_hashtags', 0)}")
        
        # ã‚µãƒ³ãƒ—ãƒ«ã‚¿ã‚°CSVä½œæˆ
        sample_csv = create_sample_tags_csv()
        
        print("\nğŸ‰ ãƒ‡ãƒ¼ã‚¿ç®¡ç†æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    import time
    main()